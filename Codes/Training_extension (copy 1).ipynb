{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gpu_to_use(minimum_memory_mb = 3800):\n",
    "    gpu_to_use = None\n",
    "    try: \n",
    "        os.environ['CUDA_VISIBLE_DEVICES']\n",
    "        print('GPU already assigned before: ' + str(os.environ['CUDA_VISIBLE_DEVICES']))\n",
    "        return\n",
    "    except:\n",
    "        pass\n",
    "    torch.cuda.empty_cache()\n",
    "    for i in range(16):\n",
    "        free_memory = !nvidia-smi --query-gpu=memory.free -i $i --format=csv,nounits,noheader\n",
    "        if free_memory[0] == 'No devices were found':\n",
    "            break\n",
    "        free_memory = int(free_memory[0])\n",
    "        if free_memory>2*minimum_memory_mb:\n",
    "            gpu_to_use = i\n",
    "            break\n",
    "    if gpu_to_use is None:\n",
    "        print('Could not find any GPU available with the required free memory of ' +str(minimum_memory_mb) + 'MB. Please use a different system for this assignment.')\n",
    "    else:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_to_use)\n",
    "        print('Chosen GPU: ' + str(gpu_to_use))\n",
    "        x = torch.rand((256,1024,minimum_memory_mb-500)).cuda()\n",
    "        x = torch.rand((1,1)).cuda()\n",
    "        del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "define_gpu_to_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = pd.read_csv('train_filenames.csv', header=None)\n",
    "test_list = pd.read_csv('test_filenames.csv', header=None)\n",
    "val_list = pd.read_csv('val_filenames.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sr = '/home/sci/amanpreet/Documents/HW/CV/Project/Codes/celebA/Down_sampled/Train/'\n",
    "test_sr = '/home/sci/amanpreet/Documents/HW/CV/Project/Codes/celebA/Down_sampled/Test/'\n",
    "val_sr = '/home/sci/amanpreet/Documents/HW/CV/Project/Codes/celebA/Down_sampled/Val/'\n",
    "\n",
    "hr = \"//home/sci/amanpreet/Documents/HW/CV/Project/Codes/celebA/row_col_trim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SR_Data(Dataset):\n",
    "    \n",
    "    def __init__(self, sr_folder, hr_folder, file_list):\n",
    "        self.sr_folder = sr_folder\n",
    "        self.hr_folder = hr_folder\n",
    "        self.file_list = file_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        set_of_transforms = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "        return set_of_transforms(Image.open(self.sr_folder+str(self.file_list[idx])).convert('RGB')), set_of_transforms(Image.open(self.hr_folder+str(self.file_list[idx])).convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SR_Data(train_sr, hr, train_list[0])\n",
    "test_data = SR_Data(test_sr, hr, test_list[0])\n",
    "val_data = SR_Data(val_sr, hr, val_list[0])\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.convolution_layer_0 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 5, stride = 1, padding = 2)\n",
    "        self.prelu0 = nn.PReLU()\n",
    "        self.rb_0 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.rb_1 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.rb_2 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.rb_3 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.rb_4 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.convolution_layer_1 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.convolution_layer_2 = nn.Conv2d(in_channels = 64, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.shuffle_1 = nn.PixelShuffle(2)\n",
    "        self.prelu1 = nn.PReLU()        \n",
    "        self.convolution_layer_3 = nn.Conv2d(in_channels = 64, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.shuffle_2 = nn.PixelShuffle(2)\n",
    "        self.convolution_layer_4 = nn.Conv2d(in_channels = 64, out_channels = 3, kernel_size = 5, stride = 1, padding = 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layer_0(x)\n",
    "        x = self.prelu0(x)\n",
    "        \n",
    "        residual1 = x\n",
    "        \n",
    "        x = self.rb_0(x)\n",
    "        x += residual1\n",
    "        \n",
    "        residual2 = x\n",
    "        \n",
    "        x = self.rb_1(x)\n",
    "        \n",
    "        x += residual2\n",
    "        \n",
    "        residual3 = x\n",
    "        \n",
    "        x = self.rb_2(x)\n",
    "        \n",
    "        x += residual3\n",
    "        \n",
    "        residual4 = x\n",
    "        \n",
    "        x = self.rb_3(x)\n",
    "        \n",
    "        x += residual4\n",
    "        \n",
    "        residual5 = x\n",
    "        \n",
    "        x = self.rb_4(x)\n",
    "        \n",
    "        x += residual5\n",
    "\n",
    "        x = self.convolution_layer_1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x += residual1\n",
    "        \n",
    "        x = self.convolution_layer_2(x)\n",
    "               \n",
    "        x = self.shuffle_1(x)\n",
    "        x = self.prelu1(x)\n",
    "        x = self.convolution_layer_3(x)\n",
    "        x = self.shuffle_2(x)\n",
    "        \n",
    "        x = self.convolution_layer_4(x)\n",
    "        \n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            Flatten(),\n",
    "            nn.Linear(in_features = 40960, out_features= 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=1024, out_features= 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen = Generator()\n",
    "Dis = Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/sci/amanpreet/Documents/HW/CV/Project/Codes/Models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen.load_state_dict(torch.load(model_path+'Shuffler_Gen_14.pth'))\n",
    "Dis.load_state_dict(torch.load(model_path+'Shuffler_Dis_14.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen = Gen.cuda()\n",
    "Dis = Dis.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle = True, batch_size = 16, num_workers = 8)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size = 16, num_workers = 8)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 16, num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "vgg = models.vgg19(pretrained=True)\n",
    "class Identity(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier = Identity()\n",
    "vgg = vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerG = torch.optim.Adam(Gen.parameters(), lr = 0.0001)\n",
    "optimizerD = torch.optim.Adam(Dis.parameters(), lr = 0.0001)\n",
    "\n",
    "loss_clf = nn.BCELoss()\n",
    "loss_content = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(15,35):\n",
    "    count = 0\n",
    "    for sr_img, hr_img in train_loader:\n",
    "               \n",
    "        # Train the Discriminator\n",
    "        \n",
    "        Dis.zero_grad()\n",
    "        \n",
    "        sr_img = sr_img.cuda()\n",
    "        hr_img = hr_img.cuda()\n",
    "        \n",
    "        out_D = Dis(hr_img)\n",
    "        \n",
    "        bsize = sr_img.size(0)\n",
    "        label = torch.full((bsize,1), 1, device='cuda')\n",
    "        \n",
    "        errD_real = loss_clf(out_D, label)\n",
    "        \n",
    "        D_x = out_D.mean().item()\n",
    "        \n",
    "        # Get the Fake images \n",
    "        \n",
    "        fake = Gen(sr_img)\n",
    "        \n",
    "        out_D_G = Dis(fake)\n",
    "        \n",
    "        label = torch.full((bsize,1), 0, device='cuda')\n",
    "\n",
    "        errD_fake = loss_clf(out_D_G, label)\n",
    "        errD = errD_fake + errD_real\n",
    "        \n",
    "        errD.backward(retain_graph=True)\n",
    "        D_G_x = out_D_G.mean().item()\n",
    "        \n",
    "        # Update Discriminator\n",
    "        \n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Train the Generator\n",
    "        \n",
    "        Gen.zero_grad()\n",
    "        \n",
    "        # pass both the Hr and fake to VGG and compute mse on that.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_vgg = vgg(fake)\n",
    "\n",
    "            hr_vgg = vgg(hr_img)\n",
    "        \n",
    "        errG = torch.dist(fake_vgg, hr_vgg)\n",
    "        \n",
    "        err_g_mse = loss_content(fake,hr_img)\n",
    "        \n",
    "        errG = 0.006*errG + err_g_mse\n",
    "        \n",
    "        out_D_G_1 = Dis(fake)\n",
    "        label = torch.full((bsize,1), 1, device='cuda')\n",
    "        e_g = loss_clf(out_D_G_1, label)\n",
    "        D_G_1 = out_D_G_1.mean().item()\n",
    "        \n",
    "        errG = errG + 0.001*e_g # Check paper perceptual loss\n",
    "        \n",
    "        errG.backward(retain_graph=True)\n",
    "        \n",
    "        # Update the Generator\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "        if count%100 == 0:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                print(count)\n",
    "                \n",
    "                print(\"#########################Stats#####################\")\n",
    "                \n",
    "                print(\"D_x : \", D_x, \" D_G_x : \", D_G_x, \" D_G_x_1 : \", D_G_1, \" Error : \", errG.item())\n",
    "                \n",
    "                f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "                c = 0\n",
    "                for sr, hr in val_loader:\n",
    "                    if c == 0:\n",
    "                        sr_rel = sr.cuda()\n",
    "                        hr_rel = hr.cuda()\n",
    "                        fk = Gen(sr_rel)\n",
    "                    c = c + 1\n",
    "                \n",
    "                img = np.transpose(hr_rel.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                img = (img)*255\n",
    "                img = img.astype(np.uint8)\n",
    "                ax1.imshow(img)\n",
    "                ax1.set_title('Ground truth')\n",
    "                \n",
    "                imgf = np.transpose(fk.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                imgf = (imgf)*255\n",
    "                imgf = imgf.astype(np.uint8)\n",
    "                ax2.imshow(imgf)\n",
    "                ax2.set_title('Super Resolution')\n",
    "                \n",
    "                imgi = np.transpose(sr_rel.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                imgi = (imgi)*255\n",
    "                imgi = imgi.astype(np.uint8)\n",
    "                ax3.imshow(imgi)\n",
    "                ax3.set_title('Input')\n",
    "                \n",
    "                plt.show()\n",
    "    \n",
    "    torch.save(Gen.state_dict(),model_path+'Shuffler_Gen_'+str(epoch)+'.pth')\n",
    "    torch.save(Dis.state_dict(),model_path+'Shuffler_Dis_'+str(epoch)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(35,65):\n",
    "    count = 0\n",
    "    for sr_img, hr_img in train_loader:\n",
    "               \n",
    "        # Train the Discriminator\n",
    "        \n",
    "        Dis.zero_grad()\n",
    "        \n",
    "        sr_img = sr_img.cuda()\n",
    "        hr_img = hr_img.cuda()\n",
    "        \n",
    "        out_D = Dis(hr_img)\n",
    "        \n",
    "        bsize = sr_img.size(0)\n",
    "        label = torch.full((bsize,1), 1, device='cuda')\n",
    "        \n",
    "        errD_real = loss_clf(out_D, label)\n",
    "        \n",
    "        D_x = out_D.mean().item()\n",
    "        \n",
    "        # Get the Fake images \n",
    "        \n",
    "        fake = Gen(sr_img)\n",
    "        \n",
    "        out_D_G = Dis(fake)\n",
    "        \n",
    "        label = torch.full((bsize,1), 0, device='cuda')\n",
    "\n",
    "        errD_fake = loss_clf(out_D_G, label)\n",
    "        errD = errD_fake + errD_real\n",
    "        \n",
    "        errD.backward(retain_graph=True)\n",
    "        D_G_x = out_D_G.mean().item()\n",
    "        \n",
    "        # Update Discriminator\n",
    "        \n",
    "        optimizerD.step()\n",
    "        \n",
    "        # Train the Generator\n",
    "        \n",
    "        Gen.zero_grad()\n",
    "        \n",
    "        # pass both the Hr and fake to VGG and compute mse on that.\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fake_vgg = vgg(fake)\n",
    "\n",
    "            hr_vgg = vgg(hr_img)\n",
    "        \n",
    "        errG = torch.dist(fake_vgg, hr_vgg)\n",
    "        \n",
    "        err_g_mse = loss_content(fake,hr_img)\n",
    "        \n",
    "        errG = 0.006*errG + err_g_mse\n",
    "        \n",
    "        out_D_G_1 = Dis(fake)\n",
    "        label = torch.full((bsize,1), 1, device='cuda')\n",
    "        e_g = loss_clf(out_D_G_1, label)\n",
    "        D_G_1 = out_D_G_1.mean().item()\n",
    "        \n",
    "        errG = errG + 0.001*e_g # Check paper perceptual loss\n",
    "        \n",
    "        errG.backward(retain_graph=True)\n",
    "        \n",
    "        # Update the Generator\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        count = count + 1\n",
    "        \n",
    "        if count%100 == 0:\n",
    "            with torch.no_grad():\n",
    "                \n",
    "                print(count)\n",
    "                \n",
    "                print(\"#########################Stats#####################\")\n",
    "                \n",
    "                print(\"D_x : \", D_x, \" D_G_x : \", D_G_x, \" D_G_x_1 : \", D_G_1, \" Error : \", errG.item())\n",
    "                \n",
    "                f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "\n",
    "                c = 0\n",
    "                for sr, hr in val_loader:\n",
    "                    if c == 0:\n",
    "                        sr_rel = sr.cuda()\n",
    "                        hr_rel = hr.cuda()\n",
    "                        fk = Gen(sr_rel)\n",
    "                    c = c + 1\n",
    "                \n",
    "                img = np.transpose(hr_rel.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                img = (img)*255\n",
    "                img = img.astype(np.uint8)\n",
    "                ax1.imshow(img)\n",
    "                ax1.set_title('Ground truth')\n",
    "                \n",
    "                imgf = np.transpose(fk.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                imgf = (imgf)*255\n",
    "                imgf = imgf.astype(np.uint8)\n",
    "                ax2.imshow(imgf)\n",
    "                ax2.set_title('Super Resolution')\n",
    "                \n",
    "                imgi = np.transpose(sr_rel.cpu().numpy()[0,:,:,:], (1, 2, 0))\n",
    "                imgi = (imgi)*255\n",
    "                imgi = imgi.astype(np.uint8)\n",
    "                ax3.imshow(imgi)\n",
    "                ax3.set_title('Input')\n",
    "                \n",
    "                plt.show()\n",
    "    \n",
    "    torch.save(Gen.state_dict(),model_path+'Shuffler_Gen_'+str(epoch)+'.pth')\n",
    "    torch.save(Dis.state_dict(),model_path+'Shuffler_Dis_'+str(epoch)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python_3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
